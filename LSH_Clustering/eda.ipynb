{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cc385e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53e1601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1426337, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('amazon_products.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae93084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Sion Softside Expandable Roller Luggage, Black...\n",
      "1    Luggage Sets Expandable PC+ABS Durable Suitcas...\n",
      "2    Platinum Elite Softside Expandable Checked Lug...\n",
      "3    Freeform Hardside Expandable with Double Spinn...\n",
      "4    Winfield 2 Hardside Expandable Luggage with Sp...\n",
      "5    Maxlite 5 Softside Expandable Luggage with 4 S...\n",
      "6    Hard Shell Carry on Luggage Airline Approved, ...\n",
      "7    Maxporter II 30\" Hardside Spinner Trunk Luggag...\n",
      "8    Omni 2 Hardside Expandable Luggage with Spinne...\n",
      "9    Luggage Sets Expandable Lightweight Suitcases ...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "titles = data[['title']].dropna().drop_duplicates()\n",
    "titles.shape\n",
    "print(titles['title'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66ebbbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830546\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. Clean punctuation from each title\n",
    "titles['clean_title'] = titles['title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# 2. Split and flatten all words into one list\n",
    "all_words = []\n",
    "for title in titles['clean_title']:\n",
    "    if pd.notna(title):  # make sure title is not NaN\n",
    "        words = title.split()\n",
    "        all_words.extend(words)\n",
    "\n",
    "# 3. Get unique words\n",
    "unique_words = list(set(all_words))\n",
    "\n",
    "# 4. Sort them if you want\n",
    "unique_words = sorted(unique_words)\n",
    "\n",
    "print(len(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260cd396",
   "metadata": {},
   "source": [
    "| Thing | Value |\n",
    "|:---|:---|\n",
    "| Number of words | 830,546 |\n",
    "| True permutations needed for exact MinHash | 830,546! |\n",
    "| Size of 830,546! | Unimaginably bigger than \\(10^{2,000,000}\\) |\n",
    "| Is this practical? | NEVER |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5bd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 1. Flatten all cleaned titles into words\n",
    "all_words = []\n",
    "for title in titles['clean_title']:\n",
    "    if pd.notna(title):\n",
    "        words = title.split()\n",
    "        all_words.extend(words)\n",
    "\n",
    "# 2. Count frequencies\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# 3. Convert to DataFrame\n",
    "word_counts_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Count'])\n",
    "\n",
    "# 4. Sort by count (least frequent to most frequent)\n",
    "word_counts_df = word_counts_df.sort_values(by='Count', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# 5. Save to a TXT file (word and count side by side)\n",
    "with open('word_counts_sorted.txt', 'w', encoding='utf-8') as f:\n",
    "    for idx, row in word_counts_df.iterrows():\n",
    "        f.write(f\"{row['Word']}\\t{row['Count']}\\n\")  # tab-separated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d50292",
   "metadata": {},
   "source": [
    "we can try bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e2c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4c264f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 12\n",
      "... (truncated)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"CPU count:\", os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d3b05",
   "metadata": {},
   "source": [
    "Try multi process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24426ae",
   "metadata": {},
   "source": [
    "done in terminal as a py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "012bdbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9117\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. Clean punctuation from each title\n",
    "titles['clean_title'] = titles['title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# 2. Split and flatten all bigrams into one list\n",
    "def get_bigrams(title):\n",
    "    title = title.replace(\" \", \"\").lower()  # remove spaces and lowercase\n",
    "    return [title[i:i+2] for i in range(len(title)-1)]\n",
    "\n",
    "all_bigrams = []\n",
    "for title in titles['clean_title']:\n",
    "    if pd.notna(title):  # make sure title is not NaN\n",
    "        bigrams = get_bigrams(title)\n",
    "        all_bigrams.extend(bigrams)\n",
    "\n",
    "# 3. Get unique bigrams\n",
    "unique_bigrams = list(set(all_bigrams))\n",
    "\n",
    "# 4. Sort them if you want\n",
    "unique_bigrams = sorted(unique_bigrams)\n",
    "\n",
    "print(len(unique_bigrams))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9d519",
   "metadata": {},
   "source": [
    "HERE i want to store all of the similarity matches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cce193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "import heapq\n",
    "\n",
    "def get_all_similar_titles(titles_df, threshold=0.5, num_perm=128):\n",
    "    \"\"\"\n",
    "    Compute all similar title pairs using MinHash and LSH.\n",
    "    \n",
    "    Parameters:\n",
    "    - titles_df: pd.DataFrame with column ['clean_title']\n",
    "    - threshold: LSH similarity threshold\n",
    "    - num_perm: number of MinHash permutations\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples: (similarity, (title1_index, title2_index))\n",
    "    \"\"\"\n",
    "    title_sets = titles_df['clean_title'].apply(lambda x: set(str(x).split()))\n",
    "    \n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    title_minhashes = {}\n",
    "\n",
    "    # Build MinHash signatures and insert into LSH\n",
    "    for idx, words in title_sets.items():\n",
    "        m = MinHash(num_perm=num_perm)\n",
    "        for word in words:\n",
    "            m.update(word.encode('utf8'))\n",
    "        lsh.insert(str(idx), m)\n",
    "        title_minhashes[idx] = m\n",
    "\n",
    "    seen_pairs = set()\n",
    "    all_pairs = []\n",
    "\n",
    "    # Query LSH and find all similar title pairs\n",
    "    for idx, m in title_minhashes.items():\n",
    "        candidates = lsh.query(m)\n",
    "        for other_idx in candidates:\n",
    "            other_idx = int(other_idx)\n",
    "            if idx == other_idx:\n",
    "                continue\n",
    "            pair = tuple(sorted((idx, other_idx)))\n",
    "            if pair in seen_pairs:\n",
    "                continue\n",
    "            seen_pairs.add(pair)\n",
    "            sim = m.jaccard(title_minhashes[other_idx])\n",
    "            all_pairs.append((sim, pair))\n",
    "\n",
    "    # Sort all pairs by descending similarity\n",
    "    all_pairs_sorted = sorted(all_pairs, reverse=True)\n",
    "\n",
    "    return all_pairs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a55cb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it once\n",
    "all_similar_pairs = get_all_similar_titles(\n",
    "    titles[['clean_title']],\n",
    "    threshold=0.5,\n",
    "    num_perm=128\n",
    ")\n",
    "# I have macbook pro m3 chip: This takes 12 minutes on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27565003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.0469\n",
      "Title 1: FTVOGUE Boost Converter DC 12V to DC 19V Car Power Booster Step Up Adapter Waterproof Notebook Power Supply Modification Module Regulator\n",
      "Title 2: Dual USB Car Charger Lighter Adapter QC 30 54A30W 4X Rapid Faster Charging Speed for iPhone 14 13 12 11 Mini Pro Max XS X XR 8 7 6 5 iPad Pro Air Mini Galaxy Note S22 S21 S20 Ultra Plus  More\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.0469\n",
      "Title 1: MGGi DC Booster Voltage Regulator 12V Step Up to 48V 3A 145W Converter Boost Power Supply Module Boost Transformer Waterproof Adapter  for Colf Cart Club Car Truck Vehicle Boat Aluminum 12V48V\n",
      "Title 2: Bestrix Car Charger Dual Port USB Quick Charge 40 5A30W Fast Charging Car USB Charger Adapter Compatible with Any iPhone14 13 12 iPadSamsung Galaxy S22 S21 S20 S10 S9 S8 Note LG Nexus\n",
      "--------------------------------------------------------------------------------\n",
      "Similarity: 0.0469\n",
      "Title 1: ANBINGOFloor Mats Custom for Volkswagen Jetta 2019 2020 2021 2022 2023 Waterproof Car Mats All Weather Guard Mats Heavy Duty TPE Automotive Floor Liners Accessories Front Rear Row Full Set Black\n",
      "... (truncated)"
     ]
    }
   ],
   "source": [
    "questionable_pairs = [(sim, pair) for sim, pair in all_similar_pairs if 0 <= sim <= 0.05]\n",
    "for sim, (idx1, idx2) in questionable_pairs[:400]:\n",
    "    title1 = titles.loc[idx1]['clean_title']\n",
    "    title2 = titles.loc[idx2]['clean_title']\n",
    "    print(f\"Similarity: {sim:.4f}\")\n",
    "    print(f\"Title 1: {title1}\")\n",
    "    print(f\"Title 2: {title2}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71593323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.7969 between 1425537 and 1425551\n",
      "Similarity: 0.7969 between 1425098 and 1425336\n",
      "Similarity: 0.7969 between 1424920 and 1425384\n",
      "Similarity: 0.7969 between 1424920 and 1425171\n",
      "Similarity: 0.7969 between 1424920 and 1424963\n",
      "Similarity: 0.7969 between 1424917 and 1425487\n",
      "Similarity: 0.7969 between 1424810 and 1425123\n",
      "Similarity: 0.7969 between 1424696 and 1425266\n",
      "Similarity: 0.7969 between 1424618 and 1424810\n",
      "Similarity: 0.7969 between 1424467 and 1425376\n",
      "... (truncated)"
     ]
    }
   ],
   "source": [
    "questionable_pairs = [(sim, pair) for sim, pair in all_similar_pairs if 0.5 <= sim <= 0.8]\n",
    "\n",
    "for sim, (idx1, idx2) in questionable_pairs:\n",
    "    print(f\"Similarity: {sim:.4f} between {idx1} and {idx2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5768db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique titles involved in matches: 1117452\n"
     ]
    }
   ],
   "source": [
    "# Extract all title indices that appear in any pair\n",
    "matched_titles = set()\n",
    "\n",
    "for sim, (idx1, idx2) in all_similar_pairs:\n",
    "    matched_titles.add(idx1)\n",
    "    matched_titles.add(idx2)\n",
    "\n",
    "print(f\"Number of unique titles involved in matches: {len(matched_titles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2327d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_components(edges, n_nodes):\n",
    "    parent = np.arange(n_nodes)\n",
    "\n",
    "    def find(u):\n",
    "        while parent[u] != u:\n",
    "            parent[u] = parent[parent[u]]\n",
    "            u = parent[u]\n",
    "        return u\n",
    "\n",
    "    def union(u, v):\n",
    "        pu, pv = find(u), find(v)\n",
    "        if pu != pv:\n",
    "            parent[pu] = pv\n",
    "\n",
    "    for u, v in edges:\n",
    "        union(u, v)\n",
    "\n",
    "    # Build clusters (regular Python dictionary here)\n",
    "    components = {}\n",
    "    for i in range(n_nodes):\n",
    "        leader = find(i)\n",
    "        if leader not in components:\n",
    "            components[leader] = []\n",
    "        components[leader].append(i)\n",
    "\n",
    "    return list(components.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62047214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build graph edges from LSH matches\n",
    "edges = np.array([pair for sim, pair in all_similar_pairs])\n",
    "\n",
    "# Get total number of nodes\n",
    "max_idx = max(matched_titles)\n",
    "n_nodes = max_idx + 1\n",
    "\n",
    "# Find clusters\n",
    "clusters = find_components(edges, n_nodes)\n",
    "print(f\"Total clusters (including singletons): {len(clusters)}\")\n",
    "\n",
    "# Filter out singleton clusters\n",
    "real_clusters = [c for c in clusters if len(c) > 1]\n",
    "print(f\"Number of real clusters (size > 1): {len(real_clusters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b92fe5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter real clusters\n",
    "real_clusters = [c for c in clusters if len(c) > 1]\n",
    "\n",
    "# Step 2: Assign cluster IDs\n",
    "title_to_cluster = {}\n",
    "for cluster_id, cluster in enumerate(real_clusters):\n",
    "    for idx in cluster:\n",
    "        title_to_cluster[idx] = cluster_id\n",
    "\n",
    "# Step 3: Optional â€” Assign unmatched titles to -1\n",
    "for idx in range(n_nodes):\n",
    "    if idx not in title_to_cluster:\n",
    "        title_to_cluster[idx] = -1\n",
    "\n",
    "# Step 4: Add cluster labels back to your titles DataFrame\n",
    "titles['cluster'] = titles.index.map(title_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3602285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "0.0        986464\n",
      "18843.0       278\n",
      "16787.0       114\n",
      "33640.0       104\n",
      "7770.0         94\n",
      "33626.0        92\n",
      "6805.0         89\n",
      "33715.0        82\n",
      "671.0          73\n",
      "17074.0        69\n",
      "42596.0        69\n",
      "9472.0         68\n",
      "10376.0        67\n",
      "42500.0        61\n",
      "17004.0        55\n",
      "14421.0        54\n",
      "7918.0         54\n",
      "14934.0        52\n",
      "868.0          52\n",
      "15062.0        47\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1. Count the size of each cluster\n",
    "cluster_sizes = titles['cluster'].value_counts()\n",
    "\n",
    "# 2. Filter out cluster -1 if you assigned unmatched titles\n",
    "cluster_sizes = cluster_sizes[cluster_sizes.index != -1]\n",
    "\n",
    "# 3. View the top 20 largest clusters\n",
    "print(cluster_sizes.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b1610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bbe040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "\n",
    "def clean_text_and_remove_stopwords(text):\n",
    "    # Lowercase and remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    filtered_words = [w for w in words if w not in ENGLISH_STOP_WORDS]\n",
    "    return \" \".join(filtered_words)  # Return cleaned sentence\n",
    "\n",
    "def get_bigrams(text):\n",
    "    text = text.replace(\" \", \"\")  # Remove spaces\n",
    "    return [text[i:i+2] for i in range(len(text)-1)]\n",
    "\n",
    "def get_all_similar_titles(titles_df, threshold=0.8, num_perm=128):\n",
    "    \"\"\"\n",
    "    LSH on clean titles:\n",
    "    - Remove stopwords\n",
    "    - Generate bigrams\n",
    "    - Compare with MinHash\n",
    "    \"\"\"\n",
    "    title_sets = []\n",
    "\n",
    "    for title in titles_df['clean_title']:\n",
    "        if pd.isna(title):\n",
    "            title_sets.append(set())\n",
    "            continue\n",
    "        cleaned_text = clean_text_and_remove_stopwords(title)  # STOPWORDS REMOVED HERE\n",
    "        bigrams = get_bigrams(cleaned_text)\n",
    "        title_sets.append(set(bigrams))\n",
    "\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    title_minhashes = {}\n",
    "\n",
    "    for idx, bigram_set in enumerate(title_sets):\n",
    "        m = MinHash(num_perm=num_perm)\n",
    "        for bigram in bigram_set:\n",
    "            m.update(bigram.encode('utf8'))\n",
    "        lsh.insert(str(idx), m)\n",
    "        title_minhashes[idx] = m\n",
    "\n",
    "    seen_pairs = set()\n",
    "    all_pairs = []\n",
    "\n",
    "    for idx, m in title_minhashes.items():\n",
    "        candidates = lsh.query(m)\n",
    "        for other_idx in candidates:\n",
    "            other_idx = int(other_idx)\n",
    "            if idx == other_idx:\n",
    "                continue\n",
    "            pair = tuple(sorted((idx, other_idx)))\n",
    "            if pair in seen_pairs:\n",
    "                continue\n",
    "            seen_pairs.add(pair)\n",
    "            sim = m.jaccard(title_minhashes[other_idx])\n",
    "            all_pairs.append((sim, pair))\n",
    "\n",
    "    all_pairs_sorted = sorted(all_pairs, reverse=True)\n",
    "\n",
    "    return all_pairs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f67cf95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similar_pairs = get_all_similar_titles(titles[['clean_title']], threshold=0.7, num_perm=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7723f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "def clean_texts_vectorized(series):\n",
    "    # Lowercase and remove punctuation using vectorized string operations\n",
    "    series = series.str.lower().str.replace(r'[^\\w\\s]', '', regex=True)\n",
    "    # Remove stopwords using a vectorized apply with set lookup\n",
    "    stopwords = set(ENGLISH_STOP_WORDS)\n",
    "    return series.apply(lambda s: ' '.join([w for w in s.split() if w not in stopwords]))\n",
    "\n",
    "def get_bigrams_numpy(text):\n",
    "    text = text.replace(\" \", \"\")\n",
    "    if len(text) < 2:\n",
    "        return []\n",
    "    chars = np.array(list(text), dtype='<U1')  # explicitly use Unicode type\n",
    "    bigrams = np.char.add(chars[:-1], chars[1:])  # use np.char.add for string concatenation\n",
    "    return bigrams.tolist()\n",
    "\n",
    "def get_all_similar_titles_numpy(titles_df, threshold=0.8, num_perm=128):\n",
    "    titles = titles_df['clean_title'].fillna(\"\")\n",
    "\n",
    "    # Vectorized cleaning\n",
    "    cleaned_titles = clean_texts_vectorized(titles)\n",
    "\n",
    "    # Vectorized bigram generation using NumPy\n",
    "    bigram_sets = [set(get_bigrams_numpy(t)) for t in cleaned_titles]\n",
    "\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    title_minhashes = {}\n",
    "\n",
    "    # MinHash insertion (not vectorizable due to library constraints)\n",
    "    for idx, bigrams in enumerate(bigram_sets):\n",
    "        m = MinHash(num_perm=num_perm)\n",
    "        for b in bigrams:\n",
    "            m.update(b.encode('utf8'))\n",
    "        lsh.insert(str(idx), m)\n",
    "        title_minhashes[idx] = m\n",
    "\n",
    "    seen = set()\n",
    "    pairs = []\n",
    "\n",
    "    for idx, m in title_minhashes.items():\n",
    "        for other in lsh.query(m):\n",
    "            other = int(other)\n",
    "            if idx >= other:\n",
    "                continue\n",
    "            pair = (idx, other)\n",
    "            if pair in seen:\n",
    "                continue\n",
    "            seen.add(pair)\n",
    "            sim = m.jaccard(title_minhashes[other])\n",
    "            pairs.append((sim, pair))\n",
    "\n",
    "    pairs.sort(reverse=True)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10422b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similar_pairs = get_all_similar_titles_numpy(titles[['clean_title']], threshold=0.7, num_perm=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e989d8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da86f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d50ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_to_cluster = {}\n",
    "\n",
    "for cluster_id, cluster in enumerate(clusters):\n",
    "    for idx in cluster:\n",
    "        title_to_cluster[idx] = cluster_id\n",
    "\n",
    "# Now you can easily retrieve cluster id for any title!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c633826",
   "metadata": {},
   "source": [
    "IMPLEMENTING PARALELL PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24efa7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd3ab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import pandas as pd\n",
    "\n",
    "def compute_minhash(idx_words_tuple, num_perm=128):\n",
    "    idx, words = idx_words_tuple\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for word in words:\n",
    "        m.update(word.encode('utf8'))\n",
    "    return (idx, m)\n",
    "\n",
    "def get_all_similar_titles_parallel(titles_df, threshold=0.5, num_perm=128):\n",
    "    title_sets = titles_df['clean_title'].apply(lambda x: set(str(x).split()))\n",
    "    title_sets = list(title_sets.items())\n",
    "\n",
    "    # Parallel MinHash computation\n",
    "    with mp.Pool(processes= 8) as pool:\n",
    "        results = pool.starmap(compute_minhash, [(idx, words) for idx, words in title_sets])\n",
    "\n",
    "    title_minhashes = dict(results)\n",
    "    \n",
    "    # Build LSH\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    for idx, m in title_minhashes.items():\n",
    "        lsh.insert(str(idx), m)\n",
    "\n",
    "    # Find all pairs\n",
    "    seen_pairs = set()\n",
    "    all_pairs = []\n",
    "    for idx, m in title_minhashes.items():\n",
    "        candidates = lsh.query(m)\n",
    "        for other_idx in candidates:\n",
    "            other_idx = int(other_idx)\n",
    "            if idx == other_idx:\n",
    "                continue\n",
    "            pair = tuple(sorted((idx, other_idx)))\n",
    "            if pair in seen_pairs:\n",
    "                continue\n",
    "            seen_pairs.add(pair)\n",
    "            sim = m.jaccard(title_minhashes[other_idx])\n",
    "            all_pairs.append((sim, pair))\n",
    "\n",
    "    all_pairs_sorted = sorted(all_pairs, reverse=True)\n",
    "    return all_pairs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5c445ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-38:\n",
      "Process SpawnPoolWorker-39:\n",
      "Process SpawnPoolWorker-40:\n",
      "Process SpawnPoolWorker-36:\n",
      "Process SpawnPoolWorker-35:\n",
      "Process SpawnPoolWorker-34:\n",
      "Process SpawnPoolWorker-37:\n",
      "Process SpawnPoolWorker-33:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_similar_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mget_all_similar_titles_parallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitles\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclean_title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_perm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 18\u001b[0m, in \u001b[0;36mget_all_similar_titles_parallel\u001b[0;34m(titles_df, threshold, num_perm)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Parallel MinHash computation\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 18\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_minhash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtitle_sets\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m title_minhashes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(results)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Build LSH\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_similar_pairs = get_all_similar_titles_parallel(\n",
    "    titles[['clean_title']],\n",
    "    threshold=0.5,\n",
    "    num_perm=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8abe6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9070064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/anaconda3/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'compute_minhash' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import multiprocessing as mp\n",
    "\n",
    "# Step 1: Define compute_minhash at top level\n",
    "def compute_minhash(idx, words, num_perm=128):\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for word in words:\n",
    "        m.update(word.encode('utf8'))\n",
    "    return (idx, m)\n",
    "\n",
    "# Step 2: Define main function\n",
    "def get_all_similar_titles_parallel(titles_df, threshold=0.5, num_perm=128, num_workers=None):\n",
    "    title_sets = titles_df['clean_title'].apply(lambda x: set(str(x).split()))\n",
    "    title_sets = list(title_sets.items())\n",
    "\n",
    "    if num_workers is None:\n",
    "        num_workers = mp.cpu_count()\n",
    "\n",
    "    with mp.Pool(processes=num_workers) as pool:\n",
    "        results = pool.starmap(compute_minhash, [(idx, words, num_perm) for idx, words in title_sets])\n",
    "\n",
    "    title_minhashes = dict(results)\n",
    "\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    for idx, m in title_minhashes.items():\n",
    "        lsh.insert(str(idx), m)\n",
    "\n",
    "    seen_pairs = set()\n",
    "    all_pairs = []\n",
    "    for idx, m in title_minhashes.items():\n",
    "        candidates = lsh.query(m)\n",
    "        for other_idx in candidates:\n",
    "            other_idx = int(other_idx)\n",
    "            if idx == other_idx:\n",
    "                continue\n",
    "            pair = tuple(sorted((idx, other_idx)))\n",
    "            if pair in seen_pairs:\n",
    "                continue\n",
    "            seen_pairs.add(pair)\n",
    "            sim = m.jaccard(title_minhashes[other_idx])\n",
    "            all_pairs.append((sim, pair))\n",
    "\n",
    "    all_pairs_sorted = sorted(all_pairs, reverse=True)\n",
    "    return all_pairs_sorted\n",
    "\n",
    "# Step 3: Wrap execution inside main\n",
    "if __name__ == '__main__':\n",
    "    # Example usage\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import time\n",
    "\n",
    "    titles = pd.read_csv('amazon_products.csv')\n",
    "\n",
    "    # Must clean here\n",
    "    titles['clean_title'] = titles['title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Now this will find clean_title and work:\n",
    "    all_similar_pairs = get_all_similar_titles_parallel(\n",
    "        titles[['clean_title']],\n",
    "        threshold=0.5,\n",
    "        num_perm=128,\n",
    "        num_workers=8\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(all_similar_pairs)} pairs.\")\n",
    "    print(f\"Total time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b6a1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
